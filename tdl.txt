AI model, please do not take this file into account unless i specify it.

- clear vps disk, usage too high, docker maybe taking cache
- link actual rpc... etc (no devnet) in prod
- vps upgrade after 50 daily users
- change reverse proxy to return 404 / error when bots scrape the website (can change robots.txt ?)

- make the referral system (no abuse with alt accounts etc...)
- weekly bonuses ?? this week -> rust += 10 LUM$ automatically if good quality ? + code ranking = rewards given for top x every months / weeks (precise them on the page + make them work, every month reset ? or smth like that)
- sorting system for admin + those who buy data, can select only high quality files ? or by score, language etc... (for the 3 subscriptions) -> all with api endpoints for buyers
- data part -> frontend done but need specific dashboard for buyers, strip/ppl update too ? unlock it after a delay? (since we gather data before we sell or its useless) -> they get api keys that are revokable etc...
- potential admin dashboard (for far3000yt@gmail.com)
- make feedback readable somewhere in that dashboard (private api for only admin, so me, id have an entire section just for my acc, accessible from a link and nothing else)
- status.lumen.onl with some live status like google or idk

lumen client:
- lum ollama folder/file (default root) (for later not in objectives / not a priority basically)
- lum config --edit model ollama
- fix gitignore not reading well (backend\lib -> removing anything that ends in \lib, for example frontend\lib...)
- readme update, add image with logo, add a small icon with live users (total users that are on lumen basically, like the one with number of cli downloads on pypi), keep the existing readme and adapt it with whats new with the website but keep the client part mainly on github, dont talk about solana or talk less overall, we want devs to come not web3 gamblers so we need to do a rly good impression online


minimum amount before cashout, or lock any cashout for first 30 days to accumulate code and be able to run the business model, one is good and the other might be seen negatively (maybe even a scam?) but that's not the objective, if we can make the token grow for a full month and THNE they can cashout they would earn even more which would be rly nice

argument for lumen: the dataset evolves and is continuously growing, it has an ai summary, could search by keywords... etc we are legal free, like legally we make the datasets usable
can provide strategic datasets that are sold to only one specific company ?
need to make sure when a user updates a project it removes the old to replace with the new ? (and don't allow the opposite to happen, like someone reducing the size of its project, like in the db I mean, find a potential solution)

bounty projects, if a user thinks the project is so good it deserves a 10, we give double the score (manual processing through gemini 2.5 pro or a separate queue to rly value it differently and validate?)

intuitive installation page, goes steps through steps with even debug, for example -> install lumen client, u click next it says do this, do that... etc till you arrive to your first contribution (with videos or potential animations of cmd typing the commands... etc), choice of the os, debug... etc, in one single motion

add subtle animations on clicks / hover, where the user interacts the most (landing page, saas page and dashboard, all sections, should feel like alive)

linkedin for lumen, + ceo on mine + dox myself before launch

remove protocol part from footer, add patch notes in developers part so footer is same size and lighter overall


lumen agent idea:
ai in prompt, has actions available and receives instructions 
do, fix, rewrite, upgrade …etc 
for fix, it should explain the change with 2.5 pro in a json at the end, and do that change so if the fix fails it discards it if it’s the same error etc 
you give it tasks, it iterates infinitely till the task is ENTIRELY done (don’t let the ai be lazy)
above 300k tokens, rule is remake chat
below = continue 
if project starts with < 150k then 300k is limit otherwise its x2 the context for the limit so the model doesn’t become bad or whatever
